{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "NLP2 -tfidf",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/prateekmaj21/tf-idf-in-python"
   ],
   "metadata": {
    "id": "Oo-yx-U6zi4k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ],
   "metadata": {
    "id": "3J2m-CaSyvno",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 1. Реализовать tfidf датасета"
   ],
   "metadata": {
    "id": "uCoqd04B2UMZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "data = list(open(os.path.join('data', 'quora.txt'), encoding=\"utf-8\"))\n",
    "data[50]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2lQgtHA2TBr",
    "outputId": "f7c13501-cbb1-4746-a3ca-fde1f8b9c5fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "\"What TV shows or books help you read people's body language?\\n\""
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 3069)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "word_count = count.fit_transform(data[:1000])\n",
    "word_count.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names_out(),columns=[\"idf_weights\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "      idf_weights\nwhat     1.960720\nthe      1.995252\nis       2.131102\nhow      2.332806\nin       2.423958",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idf_weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>what</th>\n      <td>1.960720</td>\n    </tr>\n    <tr>\n      <th>the</th>\n      <td>1.995252</td>\n    </tr>\n    <tr>\n      <th>is</th>\n      <td>2.131102</td>\n    </tr>\n    <tr>\n      <th>how</th>\n      <td>2.332806</td>\n    </tr>\n    <tr>\n      <th>in</th>\n      <td>2.423958</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inverse document frequency\n",
    "df_idf.sort_values(by=['idf_weights']).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "              tfidf\nfast       0.440432\naddiction  0.440432\nways       0.440432\novercome   0.398123\nfood       0.355814",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fast</th>\n      <td>0.440432</td>\n    </tr>\n    <tr>\n      <th>addiction</th>\n      <td>0.440432</td>\n    </tr>\n    <tr>\n      <th>ways</th>\n      <td>0.440432</td>\n    </tr>\n    <tr>\n      <th>overcome</th>\n      <td>0.398123</td>\n    </tr>\n    <tr>\n      <th>food</th>\n      <td>0.355814</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "tf_idf_vector = tfidf_transformer.transform(word_count)\n",
    "feature_names = count.get_feature_names_out()\n",
    "first_document_vector=tf_idf_vector[1]\n",
    "df_tfifd = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df_tfifd.sort_values(by=[\"tfidf\"],ascending=False).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 2. Находим косинусное расстояние по вектору tfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82402803]]\n",
      "What universities does Wabash National recruit new grads from? What majors are they looking for?\n",
      "\n",
      "What universities does PetMeds recruit new grads from? What majors are they looking for?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_cos = 0\n",
    "v1 = None\n",
    "v2 = None\n",
    "pos1 = None\n",
    "pos2 = None\n",
    "for i in range(word_count.shape[0]):\n",
    "    for j in range(i+1, word_count.shape[0]-1):\n",
    "        cos = dot(tf_idf_vector[i].todense(), tf_idf_vector[j].T.todense())/(norm(tf_idf_vector[i].T.todense())*norm(tf_idf_vector[j].T.todense()))\n",
    "        if max_cos < cos:\n",
    "            max_cos = cos\n",
    "            v1 = tf_idf_vector[i]\n",
    "            v2 = tf_idf_vector[j]\n",
    "            pos1 = i\n",
    "            pos2 = j\n",
    "print(max_cos)\n",
    "print(data[pos1], data[pos2], sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 3. Находим самые схожие предложения по вектору из BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def vectorize(tokens):\n",
    "    ''' This function takes list of words in a sentence as input\n",
    "    and returns a vector of size of filtered_vocab.It puts 0 if the\n",
    "    word is not present in tokens and count of token if present.'''\n",
    "    vector=[]\n",
    "    for w in filtered_vocab:\n",
    "        vector.append(tokens.count(w))\n",
    "    return vector\n",
    "def unique(sequence):\n",
    "    '''This functions returns a list in which the order remains\n",
    "    same and no item repeats.Using the set() function does not\n",
    "    preserve the original ordering,so i didnt use that instead'''\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "#create a list of stopwords.You can import stopwords from nltk too\n",
    "stopwords=[\"to\",\"is\",\"a\"]\n",
    "\n",
    "#list of special characters.You can use regular expressions too\n",
    "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "data_lower = [i.lower() for i in data[:1000]]\n",
    "data_tok = [tokenizer.tokenize(i) for i in data_lower]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in data_tok:\n",
    "    for j in i:\n",
    "        all_words.append(j)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "vocab = unique(all_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "filtered_vocab = []\n",
    "for w in vocab:\n",
    "    if w not in stopwords and w not in special_char:\n",
    "        filtered_vocab.append(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "vector_of_data_tok = []\n",
    "for i in data_tok:\n",
    "    vector_of_data_tok.append(vectorize(i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9095085938862486\n",
      "['what', 'universities', 'does', 'wabash', 'national', 'recruit', 'new', 'grads', 'from', '?', 'what', 'majors', 'are', 'they', 'looking', 'for', '?']\n",
      "['what', 'universities', 'does', 'petmeds', 'recruit', 'new', 'grads', 'from', '?', 'what', 'majors', 'are', 'they', 'looking', 'for', '?']\n"
     ]
    }
   ],
   "source": [
    "max_cos = 0\n",
    "v1 = None\n",
    "v2 = None\n",
    "pos1 = None\n",
    "pos2 = None\n",
    "for i in range(len(vector_of_data_tok)):\n",
    "    for j in range(i+1, len(vector_of_data_tok)-1):\n",
    "        cos = dot(vector_of_data_tok[i], vector_of_data_tok[j])/(norm(vector_of_data_tok[i])*norm(vector_of_data_tok[j]))\n",
    "        if max_cos < cos:\n",
    "            max_cos = cos\n",
    "            v1 = vector_of_data_tok[i]\n",
    "            v2 = vector_of_data_tok[j]\n",
    "            pos1 = i\n",
    "            pos2 = j\n",
    "print(max_cos)\n",
    "print(data_tok[pos1], data_tok[pos2], sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What universities does Wabash National recruit new grads from? What majors are they looking for?\n",
      "\n",
      "What universities does PetMeds recruit new grads from? What majors are they looking for?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[pos1], data[pos2], sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод:** TF-IDF и BoW справились одинаково хорошо с поиском похожих предложений. Косинусная мера при применении BoW выше"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}