{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "in0PyicHhZDG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# архитектура модели\n",
    "# загрузчик данных\n",
    "# формирование батча\n",
    "# инициализировать модель\n",
    "# оптимизатор\n",
    "# функция потерь\n",
    "# опционально шедулеры -\n",
    "# трейн луп"
   ],
   "metadata": {
    "id": "73ieMA485Tme",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = datasets.MNIST('.', download=True)"
   ],
   "metadata": {
    "id": "SI8UCZuy7hTK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "id": "dhJuBtoz7f43",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "83a61300-7937-4cb3-f803-93b2b2db4b1b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7F3CCA01DF90>, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(dataset.data[0].detach().numpy())\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "0zXXXYP37gFL",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "outputId": "2dc20aa4-aaf8-42a6-967c-1e942bd5e381"
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBQHXoJrrRor",
    "outputId": "5c2050f9-61fa-4d9a-fe72-553e8ef7c943"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# разбиваем датасет на тренировочный и тестовый\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [50000, 10000], generator=torch.Generator().manual_seed(42))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "z7TrU-_RrRor"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # custom веса nn.init.xavier_normal_(self.linear_weight)\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "LdAH7oiY8Mxv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Формирование батча\n",
    "\n",
    "def collate_fn(data: list):\n",
    "  # data = [(pic, target)...]\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "        pics.append(np.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    pics = torch.from_numpy(np.array(pics)).float() / 255 # B x W x H нормируем чтобы были числа от 0 до 1\n",
    "    #target = torch.from_numpy(np.array(target)).type(torch.LongTensor)\n",
    "    target = torch.as_tensor(np.array(target), dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        'data': pics.view(pics.size(0), -1),\n",
    "        'target': target, # классы\n",
    "        }\n"
   ],
   "metadata": {
    "id": "aImjm1_u8NR8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# hyperparams Управление девайсом\n",
    "inp_dim = 28 * 28\n",
    "hidden = 256\n",
    "out_dim = 10\n",
    "device_id = 0\n",
    "device = 'cpu' if device_id == -1 else f'cuda:{device_id}' # видеокарта cuda - 1 процессор, 0 гпу\n",
    "n_epochs = 10\n",
    "batch_size = 128"
   ],
   "metadata": {
    "id": "uPJauY4hAqJ6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# инициализация модели\n",
    "model = LinearModel(inp_dim, hidden, out_dim).to(device)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "id": "_fdZfq9C9zO2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for epoch in range(n_epochs):\n",
    "    # каждый раз случайное разбиение, поэтому каждый раз новый загрузчик\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last = True\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model.state_dict(), f'./chkpt_cv1_{epoch}.pth')\n"
   ],
   "metadata": {
    "id": "4p52DhoFBYTr",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f87bd231-e802-46c2-a890-e251a5562b1c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0, step: 0, loss: 2.306894540786743\n",
      "epoch: 0, step: 200, loss: 0.29865315556526184\n",
      "epoch: 1, step: 0, loss: 0.2522173821926117\n",
      "epoch: 1, step: 200, loss: 0.10328377038240433\n",
      "epoch: 2, step: 0, loss: 0.17839650809764862\n",
      "epoch: 2, step: 200, loss: 0.10507255792617798\n",
      "epoch: 3, step: 0, loss: 0.11596290022134781\n",
      "epoch: 3, step: 200, loss: 0.04517514258623123\n",
      "epoch: 4, step: 0, loss: 0.09865587204694748\n",
      "epoch: 4, step: 200, loss: 0.06307872384786606\n",
      "epoch: 5, step: 0, loss: 0.06813845783472061\n",
      "epoch: 5, step: 200, loss: 0.0577332079410553\n",
      "epoch: 6, step: 0, loss: 0.11204257607460022\n",
      "epoch: 6, step: 200, loss: 0.07631662487983704\n",
      "epoch: 7, step: 0, loss: 0.03637488931417465\n",
      "epoch: 7, step: 200, loss: 0.02607671171426773\n",
      "epoch: 8, step: 0, loss: 0.041029516607522964\n",
      "epoch: 8, step: 200, loss: 0.01631963811814785\n",
      "epoch: 9, step: 0, loss: 0.02501017227768898\n",
      "epoch: 9, step: 200, loss: 0.0392017588019371\n",
      "CPU times: user 23 s, sys: 531 ms, total: 23.5 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = collate_fn(test_dataset)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "8QiNuotNrRou"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Корректных ответов: 9740\n",
      "Некорректных ответов: 260\n",
      "Среднее по всем значениям функции потерь: 0.09322324070811633\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "model.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for i, pics in enumerate(test_dataset.get('data')):\n",
    "    predict = model(pics.to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset.get('target')[i].to(device)).item()]\n",
    "    predict_number = predict.data.max(0)[1]\n",
    "    if predict_number.eq(test_dataset.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERHRaecgrRou",
    "outputId": "7e7becc8-6744-4fc7-ab48-8e749a0c012b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class new_LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        #nn.init.xavier_normal_(self.linear1.weight)\n",
    "        #nn.init.kaiming_uniform_(self.linear1.weight)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.activation = nn.LogSigmoid()\n",
    "        \n",
    "        \n",
    "        #self.activation = nn.Hardswish()\n",
    "        #self.activation = nn.Tanhshrink()\n",
    "        #self.activation = nn.Softshrink()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        #x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "DDs2ZOEarRov"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = new_LinearModel(inp_dim, hidden, out_dim).to(device)\n",
    "model2.train()\n",
    "#optim = torch.optim.Adam(model2.parameters())\n",
    "optim = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "#optim = torch.optim.Adagrad(model2.parameters())\n",
    "#optim = torch.optim.RMSprop(model2.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "BzdxxY1KrRov"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0, step: 0, loss: 2.6460976600646973\n",
      "epoch: 0, step: 200, loss: 0.2086094468832016\n",
      "epoch: 1, step: 0, loss: 0.14691577851772308\n",
      "epoch: 1, step: 200, loss: 0.10619126260280609\n",
      "epoch: 2, step: 0, loss: 0.039968132972717285\n",
      "epoch: 2, step: 200, loss: 0.06169428303837776\n",
      "epoch: 3, step: 0, loss: 0.08776365965604782\n",
      "epoch: 3, step: 200, loss: 0.031325679272413254\n",
      "epoch: 4, step: 0, loss: 0.0400242805480957\n",
      "epoch: 4, step: 200, loss: 0.05220981687307358\n",
      "epoch: 5, step: 0, loss: 0.043440770357847214\n",
      "epoch: 5, step: 200, loss: 0.024050798267126083\n",
      "epoch: 6, step: 0, loss: 0.01117737777531147\n",
      "epoch: 6, step: 200, loss: 0.07905589789152145\n",
      "epoch: 7, step: 0, loss: 0.030531244352459908\n",
      "epoch: 7, step: 200, loss: 0.011733327992260456\n",
      "epoch: 8, step: 0, loss: 0.015790417790412903\n",
      "epoch: 8, step: 200, loss: 0.023358015343546867\n",
      "epoch: 9, step: 0, loss: 0.02916426584124565\n",
      "epoch: 9, step: 200, loss: 0.0145349046215415\n",
      "CPU times: user 21.4 s, sys: 577 ms, total: 22 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last = True\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model2(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model2.state_dict(), f'./chkpt_cv1_{epoch}.pth')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "res9pZgsrRov",
    "outputId": "25810854-6a1f-4377-e072-220eb6b7ae91"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Корректных ответов: 9763\n",
      "Некорректных ответов: 237\n",
      "Среднее по всем значениям функции потерь: 0.07878208914492325\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "model2.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(test_dataset.get('data')):\n",
    "    predict = model2(pics.to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset.get('target')[i].to(device)).item()]\n",
    "    predict_number = predict.data.max(0)[1]\n",
    "    if predict_number.eq(test_dataset.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKtQAANRrRow",
    "outputId": "a3ffcf81-7222-433c-ee72-c8f83ad26a72"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробовал несколько комбинаций, даже добавлял несколько слоев, но по метрике модель работала хуже. Чуть-чуть получилось улучшить метрики при добавлении нормализации перед внешним линейным слоем и использования оптимизатора SGD c momentum=0.9.\n",
    "\n",
    "Еще почему-то функция потерь не работала в PyCharm до тех пор, пока я явно не преобразовал целевые показатели в long тензор, хотя на колабе работало все без этого преобразования"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сверточная сеть"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        # уменьшит размер картинки в 2 раза\n",
    "        self.conv = nn.Conv2d(input_ch, hidden_ch, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, 5, kernel_size=3, padding=1, stride=1)\n",
    "        self.classifier = nn.Linear(5*14*14, output_dim)\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.do2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "input_ch = 1\n",
    "hidden_ch = 128\n",
    "out_dim = 10\n",
    "device_id = -1\n",
    "device = 'cpu' if device_id == -1 else f'cuda:{device_id}'\n",
    "n_epochs = 10\n",
    "batch_size = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def collate_fn_conv(data: list):\n",
    "    # data = [(pic, target)...]\n",
    "    pics = list()\n",
    "    target = list()\n",
    "    for item in data:\n",
    "        pics.append(np.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    pics = torch.from_numpy(np.array(pics)).float() / 255 # B x W x H\n",
    "    target = torch.from_numpy(np.array(target))\n",
    "\n",
    "    return {\n",
    "            'data': pics.unsqueeze(1), # B x 1 x W x H Добавляем измерение 1 это кол-во каналов\n",
    "            'target': target.long(),\n",
    "           }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "model_conv = ConvModel(input_ch, hidden_ch, out_dim).to(device)\n",
    "model_conv.train()\n",
    "optim = torch.optim.Adam(model_conv.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.2852942943573\n",
      "epoch: 0, step: 200, loss: 0.2259170264005661\n",
      "epoch: 1, step: 0, loss: 0.05172661319375038\n",
      "epoch: 1, step: 200, loss: 0.03468224033713341\n",
      "epoch: 2, step: 0, loss: 0.04158275946974754\n",
      "epoch: 2, step: 200, loss: 0.017551623284816742\n",
      "epoch: 3, step: 0, loss: 0.05009631812572479\n",
      "epoch: 3, step: 200, loss: 0.0655798688530922\n",
      "epoch: 4, step: 0, loss: 0.006988154724240303\n",
      "epoch: 4, step: 200, loss: 0.02043874002993107\n",
      "epoch: 5, step: 0, loss: 0.026885751634836197\n",
      "epoch: 5, step: 200, loss: 0.034843891859054565\n",
      "epoch: 6, step: 0, loss: 0.02834133990108967\n",
      "epoch: 6, step: 200, loss: 0.03538591414690018\n",
      "epoch: 7, step: 0, loss: 0.056265462189912796\n",
      "epoch: 7, step: 200, loss: 0.15029819309711456\n",
      "epoch: 8, step: 0, loss: 0.013453865423798561\n",
      "epoch: 8, step: 200, loss: 0.03868425264954567\n",
      "epoch: 9, step: 0, loss: 0.013909545727074146\n",
      "epoch: 9, step: 200, loss: 0.004515347070991993\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                          batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate_fn_conv,\n",
    "                          drop_last = True,\n",
    "                          )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_conv(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_conv.state_dict(), f'./chkpt_cv1_conv_{epoch}.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [50000, 10000], generator=torch.Generator().manual_seed(42))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "test_dataset_conv = collate_fn_conv(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "ConvModel(\n  (conv): Conv2d(1, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv3): Conv2d(128, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (classifier): Linear(in_features=980, out_features=10, bias=True)\n  (do1): Dropout(p=0.1, inplace=False)\n  (do2): Dropout(p=0.1, inplace=False)\n  (activation): ReLU()\n)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.train(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 9880\n",
      "Некорректных ответов: 120\n",
      "Среднее по всем значениям функции потерь: 0.04646988906469827\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(test_dataset_conv.get('data')):\n",
    "    predict = model_conv(pics.unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset_conv.get('target')[i].unsqueeze(0).to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(test_dataset_conv.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MaxPooling с 2-м сжатием"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class ConvModel_with_pooling(nn.Module):\n",
    "    def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.max_pooling = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        # уменьшит размер картинки в 2 раза\n",
    "        self.conv = nn.Conv2d(input_ch, hidden_ch, kernel_size=5, padding=2, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, 5, kernel_size=3, padding=1, stride=1)\n",
    "        self.classifier = nn.Linear(5*14*14, output_dim)\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.do2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model_conv_with_pooling = ConvModel_with_pooling(input_ch, hidden_ch, out_dim).to(device)\n",
    "model_conv_with_pooling.train()\n",
    "optim = torch.optim.Adam(model_conv_with_pooling.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.322575569152832\n",
      "epoch: 0, step: 200, loss: 0.09948688745498657\n",
      "epoch: 1, step: 0, loss: 0.14340375363826752\n",
      "epoch: 1, step: 200, loss: 0.1710178256034851\n",
      "epoch: 2, step: 0, loss: 0.056104086339473724\n",
      "epoch: 2, step: 200, loss: 0.08570950478315353\n",
      "epoch: 3, step: 0, loss: 0.12078048288822174\n",
      "epoch: 3, step: 200, loss: 0.06066570430994034\n",
      "epoch: 4, step: 0, loss: 0.03413877636194229\n",
      "epoch: 4, step: 200, loss: 0.13263563811779022\n",
      "epoch: 5, step: 0, loss: 0.03915030136704445\n",
      "epoch: 5, step: 200, loss: 0.07419252395629883\n",
      "epoch: 6, step: 0, loss: 0.02249988168478012\n",
      "epoch: 6, step: 200, loss: 0.05348501354455948\n",
      "epoch: 7, step: 0, loss: 0.05019669979810715\n",
      "epoch: 7, step: 200, loss: 0.055725570768117905\n",
      "epoch: 8, step: 0, loss: 0.06613645702600479\n",
      "epoch: 8, step: 200, loss: 0.05437961220741272\n",
      "epoch: 9, step: 0, loss: 0.04509729892015457\n",
      "epoch: 9, step: 200, loss: 0.06513094902038574\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                          batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate_fn_conv,\n",
    "                          drop_last = True,\n",
    "                          )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_conv_with_pooling(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_conv_with_pooling.state_dict(), f'./chkpt_cv1_conv_with_pooling_{epoch}.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 9801\n",
      "Некорректных ответов: 199\n",
      "Среднее по всем значениям функции потерь: 0.07278487113278638\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "model_conv_with_pooling.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(test_dataset_conv.get('data')):\n",
    "    predict = model_conv_with_pooling(pics.unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset_conv.get('target')[i].unsqueeze(0).to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(test_dataset_conv.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MaxPooling с 2-м сжатием + сжатие на Conv2d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class ConvModel_with_pooling(nn.Module):\n",
    "    def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.max_pooling = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        # уменьшит размер картинки в 2 раза\n",
    "        self.conv = nn.Conv2d(input_ch, hidden_ch, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, 5, kernel_size=3, padding=1, stride=1)\n",
    "        self.classifier = nn.Linear(5*7*7, output_dim)\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.do2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model_conv_with_pooling = ConvModel_with_pooling(input_ch, hidden_ch, out_dim).to(device)\n",
    "model_conv_with_pooling.train()\n",
    "optim = torch.optim.Adam(model_conv_with_pooling.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.2997498512268066\n",
      "epoch: 0, step: 200, loss: 0.10275885462760925\n",
      "epoch: 1, step: 0, loss: 0.12254931032657623\n",
      "epoch: 1, step: 200, loss: 0.205256387591362\n",
      "epoch: 2, step: 0, loss: 0.11813325434923172\n",
      "epoch: 2, step: 200, loss: 0.13465633988380432\n",
      "epoch: 3, step: 0, loss: 0.05376173183321953\n",
      "epoch: 3, step: 200, loss: 0.06561165302991867\n",
      "epoch: 4, step: 0, loss: 0.056025851517915726\n",
      "epoch: 4, step: 200, loss: 0.06520818918943405\n",
      "epoch: 5, step: 0, loss: 0.056372351944446564\n",
      "epoch: 5, step: 200, loss: 0.028101420029997826\n",
      "epoch: 6, step: 0, loss: 0.03088829480111599\n",
      "epoch: 6, step: 200, loss: 0.03371976688504219\n",
      "epoch: 7, step: 0, loss: 0.03975052759051323\n",
      "epoch: 7, step: 200, loss: 0.037651464343070984\n",
      "epoch: 8, step: 0, loss: 0.07360325008630753\n",
      "epoch: 8, step: 200, loss: 0.11182143539190292\n",
      "epoch: 9, step: 0, loss: 0.057277608662843704\n",
      "epoch: 9, step: 200, loss: 0.018220309168100357\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                          batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate_fn_conv,\n",
    "                          drop_last = True,\n",
    "                          )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_conv_with_pooling(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_conv_with_pooling.state_dict(), f'./chkpt_cv1_conv_with_pooling_{epoch}.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 9779\n",
      "Некорректных ответов: 221\n",
      "Среднее по всем значениям функции потерь: 0.07285896637573333\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "model_conv_with_pooling.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(test_dataset_conv.get('data')):\n",
    "    predict = model_conv_with_pooling(pics.unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset_conv.get('target')[i].unsqueeze(0).to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(test_dataset_conv.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MaxPooling без сжатия + сжатие на Conv2d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class ConvModel_with_pooling(nn.Module):\n",
    "    def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.max_pooling = nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        # уменьшит размер картинки в 2 раза\n",
    "        self.conv = nn.Conv2d(input_ch, hidden_ch, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, 5, kernel_size=3, padding=1, stride=1)\n",
    "        self.classifier = nn.Linear(5*14*14, output_dim)\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.do2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "model_conv_with_pooling = ConvModel_with_pooling(input_ch, hidden_ch, out_dim).to(device)\n",
    "model_conv_with_pooling.train()\n",
    "optim = torch.optim.Adam(model_conv_with_pooling.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.310537338256836\n",
      "epoch: 0, step: 200, loss: 0.15938109159469604\n",
      "epoch: 1, step: 0, loss: 0.1515197455883026\n",
      "epoch: 1, step: 200, loss: 0.1293402761220932\n",
      "epoch: 2, step: 0, loss: 0.0929345041513443\n",
      "epoch: 2, step: 200, loss: 0.034682098776102066\n",
      "epoch: 3, step: 0, loss: 0.02970503643155098\n",
      "epoch: 3, step: 200, loss: 0.09949753433465958\n",
      "epoch: 4, step: 0, loss: 0.0680297315120697\n",
      "epoch: 4, step: 200, loss: 0.15676115453243256\n",
      "epoch: 5, step: 0, loss: 0.09326082468032837\n",
      "epoch: 5, step: 200, loss: 0.06744071841239929\n",
      "epoch: 6, step: 0, loss: 0.014009212143719196\n",
      "epoch: 6, step: 200, loss: 0.026402056217193604\n",
      "epoch: 7, step: 0, loss: 0.002690432360395789\n",
      "epoch: 7, step: 200, loss: 0.035357117652893066\n",
      "epoch: 8, step: 0, loss: 0.038384515792131424\n",
      "epoch: 8, step: 200, loss: 0.007077234797179699\n",
      "epoch: 9, step: 0, loss: 0.029265249148011208\n",
      "epoch: 9, step: 200, loss: 0.058835018426179886\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                          batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate_fn_conv,\n",
    "                          drop_last = True,\n",
    "                          )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_conv_with_pooling(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_conv_with_pooling.state_dict(), f'./chkpt_cv1_conv_with_pooling_{epoch}.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 9820\n",
      "Некорректных ответов: 180\n",
      "Среднее по всем значениям функции потерь: 0.06817188110915332\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "model_conv_with_pooling.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(test_dataset_conv.get('data')):\n",
    "    predict = model_conv_with_pooling(pics.unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset_conv.get('target')[i].unsqueeze(0).to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(test_dataset_conv.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MaxPooling с уменьшением картинки в середине"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class ConvModel_with_pooling(nn.Module):\n",
    "    def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.max_pooling = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        # уменьшит размер картинки в 2 раза\n",
    "        self.conv = nn.Conv2d(input_ch, hidden_ch, kernel_size=5, padding=2, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, 5, kernel_size=3, padding=1, stride=1)\n",
    "        self.classifier = nn.Linear(5*14*14, output_dim)\n",
    "        self.do1 = nn.Dropout(dropout_p)\n",
    "        self.do2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model_conv_with_pooling = ConvModel_with_pooling(input_ch, hidden_ch, out_dim).to(device)\n",
    "model_conv_with_pooling.train()\n",
    "optim = torch.optim.Adam(model_conv_with_pooling.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.3614718914031982\n",
      "epoch: 0, step: 200, loss: 0.15462180972099304\n",
      "epoch: 1, step: 0, loss: 0.11088263243436813\n",
      "epoch: 1, step: 200, loss: 0.03862470015883446\n",
      "epoch: 2, step: 0, loss: 0.0060148537158966064\n",
      "epoch: 2, step: 200, loss: 0.03107054904103279\n",
      "epoch: 3, step: 0, loss: 0.010172602720558643\n",
      "epoch: 3, step: 200, loss: 0.016677362844347954\n",
      "epoch: 4, step: 0, loss: 0.08664847165346146\n",
      "epoch: 4, step: 200, loss: 0.05830168351531029\n",
      "epoch: 5, step: 0, loss: 0.009086942300200462\n",
      "epoch: 5, step: 200, loss: 0.046205274760723114\n",
      "epoch: 6, step: 0, loss: 0.013298513367772102\n",
      "epoch: 6, step: 200, loss: 0.00030108762439340353\n",
      "epoch: 7, step: 0, loss: 0.04806527495384216\n",
      "epoch: 7, step: 200, loss: 0.02047557383775711\n",
      "epoch: 8, step: 0, loss: 0.016186121851205826\n",
      "epoch: 8, step: 200, loss: 0.022527379915118217\n",
      "epoch: 9, step: 0, loss: 0.018666639924049377\n",
      "epoch: 9, step: 200, loss: 0.011855421587824821\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(train_dataset,\n",
    "                          batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate_fn_conv,\n",
    "                          drop_last = True,\n",
    "                          )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_conv_with_pooling(batch['data'].to(device))\n",
    "        loss = loss_func(predict, batch['target'].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_conv_with_pooling.state_dict(), f'./chkpt_cv1_conv_with_pooling_{epoch}.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 9878\n",
      "Некорректных ответов: 122\n",
      "Среднее по всем значениям функции потерь: 0.048880310819382086\n"
     ]
    }
   ],
   "source": [
    "#проверяем на тестовой выборке\n",
    "model_conv_with_pooling.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(test_dataset_conv.get('data')):\n",
    "    predict = model_conv_with_pooling(pics.unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, test_dataset_conv.get('target')[i].unsqueeze(0).to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(test_dataset_conv.get('target')[i]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод:** *При использовании процессора, применение MaxPooling не дает ощутимого прироста, но если использовать GPU (например, в колабе), то применение MaxPooling с уменьшением картинки в середине сети дает наилучшую метрику.\n",
    "Результаты не сохранились, так как закончился доступ к GPU, но на практике проверено*"
   ],
   "metadata": {
    "id": "AJ1095NXYXyE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Дообучение модели"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\diman/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\diman\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diman\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model_alexnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "datasets_flowers = {\n",
    "    'train': ImageFolder(\n",
    "        root='flowers/train/',\n",
    "        transform=preprocess\n",
    "    ),\n",
    "    'test': ImageFolder(\n",
    "        root='flowers/test/',\n",
    "        transform=preprocess\n",
    "    ),\n",
    "}\n",
    "\n",
    "datasets_flowers['train'].class_to_idx"
   ],
   "metadata": {
    "id": "0R7swZf1Xzuk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# hyperparams Управление девайсом\n",
    "device_id = -1\n",
    "device = 'cpu' if device_id == -1 else f'cuda:{device_id}' # видеокарта cuda - 1 процессор, 0 гпу\n",
    "n_epochs = 10\n",
    "batch_size = 128"
   ],
   "metadata": {
    "id": "CwiHbArxXzjy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_alexnet.to(device)"
   ],
   "metadata": {
    "id": "8towXANGVWws",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for param in model_alexnet.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model_alexnet.classifier[6] = torch.nn.Linear(4096, 5).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:[Parameter containing:\n",
      "tensor([[-0.0007, -0.0056, -0.0053,  ..., -0.0053, -0.0078,  0.0036],\n",
      "        [-0.0152, -0.0070, -0.0051,  ...,  0.0150, -0.0036,  0.0055],\n",
      "        [ 0.0033,  0.0097, -0.0112,  ..., -0.0031, -0.0014,  0.0064],\n",
      "        [ 0.0098,  0.0078, -0.0156,  ...,  0.0005,  0.0060, -0.0090],\n",
      "        [-0.0022, -0.0102,  0.0077,  ...,  0.0086,  0.0142, -0.0010]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0083,  0.0112, -0.0150, -0.0037, -0.0006], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params_to_update = []\n",
    "for name,param in model_alexnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "print(f\"Params to learn:{params_to_update}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(params_to_update)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 1.6226563453674316\n",
      "epoch: 1, step: 0, loss: 0.4390919804573059\n",
      "epoch: 2, step: 0, loss: 0.15636278688907623\n",
      "epoch: 3, step: 0, loss: 0.14768086373806\n",
      "epoch: 4, step: 0, loss: 0.10629848390817642\n",
      "epoch: 5, step: 0, loss: 0.11322282999753952\n",
      "epoch: 6, step: 0, loss: 0.05256054177880287\n",
      "epoch: 7, step: 0, loss: 0.05532310530543327\n",
      "epoch: 8, step: 0, loss: 0.06085313484072685\n",
      "epoch: 9, step: 0, loss: 0.04409520700573921\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(datasets_flowers['train'],\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last = True\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_alexnet(batch[0].to(device))\n",
    "        loss = loss_func(predict, batch[1].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_alexnet.state_dict(), f'./chkpt_model_alexnet_{epoch}.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_alexnet.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(datasets_flowers['train']):\n",
    "    predict = model_alexnet(pics[0].unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, torch.from_numpy(np.array(pics[1])).unsqueeze(0).long().to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(pics[1]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "id": "nYHevg-7VWt2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 3802\n",
      "Некорректных ответов: 11\n",
      "Среднее по всем значениям функции потерь: 0.0402277017851853\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение с 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_alexnet_not_tuned = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False).to(device)\n",
    "model_alexnet_not_tuned.classifier[6] = torch.nn.Linear(4096, 5).to(device)\n",
    "model_alexnet_not_tuned.train()\n",
    "optim = torch.optim.Adam(model_alexnet_not_tuned.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "id": "cLnfmb2yPvy5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\diman/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(datasets_flowers['train'],\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last = True\n",
    "                            )\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_alexnet_not_tuned(batch[0].to(device))\n",
    "        loss = loss_func(predict, batch[1].to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    #save every epoch\n",
    "    torch.save(model_alexnet_not_tuned.state_dict(), f'./chkpt_model_alexnet_not_tuned_{epoch}.pth')"
   ],
   "metadata": {
    "id": "XcyrXdAIPvwI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04bd770f276c49e2850bc149b6c57ae9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 1.6103599071502686\n",
      "epoch: 0, step: 10, loss: 1.610506296157837\n",
      "epoch: 0, step: 20, loss: 1.595742106437683\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1346c9fa10840029748eb30112f0c53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, step: 0, loss: 1.6126811504364014\n",
      "epoch: 1, step: 10, loss: 1.470076084136963\n",
      "epoch: 1, step: 20, loss: 1.4400838613510132\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8d7c8ac0fe74313a5c7ee55f615b9c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, step: 0, loss: 1.3823060989379883\n",
      "epoch: 2, step: 10, loss: 1.3015702962875366\n",
      "epoch: 2, step: 20, loss: 1.338711142539978\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3b2ab7684ff4917a7de450bfd7c90f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, step: 0, loss: 1.248781442642212\n",
      "epoch: 3, step: 10, loss: 1.2734605073928833\n",
      "epoch: 3, step: 20, loss: 1.2738271951675415\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed558d5d460f4e658c58a46f52886388"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, step: 0, loss: 1.2312602996826172\n",
      "epoch: 4, step: 10, loss: 1.232183814048767\n",
      "epoch: 4, step: 20, loss: 0.9402750134468079\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdf852afce8c48c4b71d6cba97891615"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, step: 0, loss: 1.2504042387008667\n",
      "epoch: 5, step: 10, loss: 1.237357497215271\n",
      "epoch: 5, step: 20, loss: 1.230269432067871\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3edd9ef3b18b4dd69b2093e207e92dc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, step: 0, loss: 1.155895709991455\n",
      "epoch: 6, step: 10, loss: 1.0380641222000122\n",
      "epoch: 6, step: 20, loss: 1.0225683450698853\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d91dec1fe6f6405e8664cccaa7be0d45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, step: 0, loss: 1.2125284671783447\n",
      "epoch: 7, step: 10, loss: 0.9684135317802429\n",
      "epoch: 7, step: 20, loss: 1.0287060737609863\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef2e1a368f1849238920150cf1bfb571"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, step: 0, loss: 0.8299262523651123\n",
      "epoch: 8, step: 10, loss: 0.9678186178207397\n",
      "epoch: 8, step: 20, loss: 0.9396075010299683\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af314af4d8324f548b3f9ce22fcabe52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, step: 0, loss: 1.0415371656417847\n",
      "epoch: 9, step: 10, loss: 0.7706637978553772\n",
      "epoch: 9, step: 20, loss: 1.0555088520050049\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корректных ответов: 2457\n",
      "Некорректных ответов: 1356\n",
      "Среднее по всем значениям функции потерь: 0.9053095094567722\n"
     ]
    }
   ],
   "source": [
    "model_alexnet_not_tuned.train(False)\n",
    "test_loss = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i, pics in enumerate(datasets_flowers['train']):\n",
    "    predict = model_alexnet_not_tuned(pics[0].unsqueeze(0).to(device))\n",
    "    test_loss += [loss_func(predict, torch.from_numpy(np.array(pics[1])).unsqueeze(0).long().to(device)).item()]\n",
    "    predict_number = predict.data[0].max(0)[1]\n",
    "    if predict_number.eq(pics[1]).item() is True:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "print(f'Корректных ответов: {correct}',\n",
    "      f'Некорректных ответов: {incorrect}',\n",
    "      f'Среднее по всем значениям функции потерь: {np.mean(test_loss)}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод:** *Использование предобученной модели дает колоссальную разницу в результатах. На одном и том же датасете с одним и тем же набором картинок результат отличается на порядок. Кроме того, дообучить модель значительно быстрее обучения ее с 0*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "-57Jq-CW8NmD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}