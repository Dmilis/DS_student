{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPNk9sBWMHKlS2RdNBCHahV"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "in0PyicHhZDG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446584511,
     "user_tz": -180,
     "elapsed": 1768,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "73ieMA485Tme",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446616465,
     "user_tz": -180,
     "elapsed": 31959,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "outputId": "ab77bc91-b158-48d8-fe70-db0f049e17b6",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#data_dir = 'drive/My Drive/'\n",
    "data_dir = 'data/'\n",
    "train_lang = 'en'"
   ],
   "metadata": {
    "id": "Os4tVkvmkTIp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446767084,
     "user_tz": -180,
     "elapsed": 585,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class DatasetSeq(Dataset):\n",
    "    def __init__(self, data_dir, train_lang='en'):\n",
    "\t#open file\n",
    "        with open(data_dir + train_lang + '.train', 'r', encoding='utf-8') as f:\n",
    "            train = f.read().split('\\n\\n')\n",
    "\n",
    "        # delete extra tag markup\n",
    "        train = [x for x in train if not '_ ' in x]\n",
    "\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n",
    "        self.target_vocab = {'<pad>': 0} # {p: 1, a: 2, r: 3, pu: 4}\n",
    "        self.word_vocab = {'<pad>': 0} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
    "        self.char_vocab = {'<pad>': 0} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
    "\t    \n",
    "        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n",
    "        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n",
    "        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n",
    "\n",
    "\t    #init encoded sequences lists (processed data)\n",
    "        self.encoded_sequences = []\n",
    "        self.encoded_targets = []\n",
    "        self.encoded_char_sequences = []\n",
    "        # n=1 because first value is padding\n",
    "        n_word = 1\n",
    "        n_target = 1\n",
    "        n_char = 1\n",
    "        for line in train:\n",
    "            sequence = []\n",
    "            target = []\n",
    "            chars = []\n",
    "            for item in line.split('\\n'):\n",
    "                if item != '':\n",
    "                    word, label = item.split(' ')\n",
    "\n",
    "                    if self.word_vocab.get(word) is None:\n",
    "                        self.word_vocab[word] = n_word\n",
    "                        n_word += 1\n",
    "                    if self.target_vocab.get(label) is None:\n",
    "                        self.target_vocab[label] = n_target\n",
    "                        n_target += 1\n",
    "                    for char in word:\n",
    "                        if self.char_vocab.get(char) is None:\n",
    "                            self.char_vocab[char] = n_char\n",
    "                            n_char += 1\n",
    "                    sequence.append(self.word_vocab[word])\n",
    "                    target.append(self.target_vocab[label])\n",
    "                    chars.append([self.char_vocab[char] for char in word])\n",
    "            self.encoded_sequences.append(sequence)\n",
    "            self.encoded_targets.append(target)\n",
    "            self.encoded_char_sequences.append(chars)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
    "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
    "            'target': self.encoded_targets[index], # [1, 2, 3, 4, 6] len=5\n",
    "        }"
   ],
   "metadata": {
    "id": "SI8UCZuy7hTK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446771269,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = DatasetSeq(data_dir)"
   ],
   "metadata": {
    "id": "dhJuBtoz7f43",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446776175,
     "user_tz": -180,
     "elapsed": 2358,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#padding\n",
    "# seq1 = [1, 2, 3, 4]\n",
    "# seq2 = [9, 7, 6, 4, 3, 7, 5]\n",
    "# pad seq1 equal seq2\n",
    "# seq1 = [1, 2, 3, 4, 0, 0, 0]\n",
    "# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n",
    "#                     [9, 7, 6, 4, 3, 7, 5]]"
   ],
   "metadata": {
    "id": "0zXXXYP37gFL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    data = []\n",
    "    target = []\n",
    "    for item in batch:\n",
    "        data.append(torch.as_tensor(item['data']))\n",
    "        target.append(torch.as_tensor(item['target']))\n",
    "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {'data': data, 'target': target}"
   ],
   "metadata": {
    "id": "uPJauY4hAqJ6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446778722,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#hyper params\n",
    "vocab_size = len(dataset.word_vocab) + 1\n",
    "n_classes = len(dataset.target_vocab) + 1\n",
    "n_chars = len(dataset.char_vocab) + 1\n",
    "#TODO try to use other model parameters\n",
    "emb_dim = 256\n",
    "hidden = 256\n",
    "n_epochs = 10\n",
    "batch_size = 64\n",
    "cuda_device = 0\n",
    "batch_size = 100\n",
    "if torch.cuda.is_available():\n",
    "    device = f'cuda:{cuda_device}'\n",
    "else:\n",
    "    device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "rus = {'PROPN': 'имя собственное',\n",
    " 'PUNCT': 'пунктуация',\n",
    " 'ADJ': 'прилагательное',\n",
    " 'NOUN': 'существительное',\n",
    " 'VERB': 'глагол',\n",
    " 'DET': 'определитель',\n",
    " 'ADP': 'послелог',\n",
    " 'AUX': 'вспомогательный глагол',\n",
    " 'PRON': 'местоимение',\n",
    " 'PART': 'частица ',\n",
    " 'SCONJ': 'союз подчинительный',\n",
    " 'NUM': 'числительное',\n",
    " 'ADV': 'наречие',\n",
    " 'CCONJ': 'союз сочинительный',\n",
    " 'X': 'другое',\n",
    " 'INTJ': 'междометие',\n",
    " 'SYM': 'символ'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class RNNPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x) # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
    "        hidden = self.do(hidden)\n",
    "        pred = self.clf(hidden) # B x T x N_classes\n",
    "\n",
    "        return pred"
   ],
   "metadata": {
    "id": "WBFZc1qY6HsC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446785184,
     "user_tz": -180,
     "elapsed": 2,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model_RNN = RNNPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
    "model_RNN.train()\n",
    "optim = torch.optim.Adam(model_RNN.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 3.1829702854156494\n",
      "epoch: 0, step: 100, loss: 0.19392119348049164\n",
      "epoch: 0, step: 200, loss: 0.23536968231201172\n",
      "epoch: 1, step: 0, loss: 0.17857904732227325\n",
      "epoch: 1, step: 100, loss: 0.1774771362543106\n",
      "epoch: 1, step: 200, loss: 0.15020506083965302\n",
      "epoch: 2, step: 0, loss: 0.15298433601856232\n",
      "epoch: 2, step: 100, loss: 0.11475085467100143\n",
      "epoch: 2, step: 200, loss: 0.11459320783615112\n",
      "epoch: 3, step: 0, loss: 0.089115209877491\n",
      "epoch: 3, step: 100, loss: 0.09685000777244568\n",
      "epoch: 3, step: 200, loss: 0.07078645378351212\n",
      "epoch: 4, step: 0, loss: 0.11050165444612503\n",
      "epoch: 4, step: 100, loss: 0.09401128441095352\n",
      "epoch: 4, step: 200, loss: 0.07012433558702469\n",
      "epoch: 5, step: 0, loss: 0.04284331202507019\n",
      "epoch: 5, step: 100, loss: 0.059045128524303436\n",
      "epoch: 5, step: 200, loss: 0.07682736963033676\n",
      "epoch: 6, step: 0, loss: 0.06254022568464279\n",
      "epoch: 6, step: 100, loss: 0.05435020476579666\n",
      "epoch: 6, step: 200, loss: 0.06147751584649086\n",
      "epoch: 7, step: 0, loss: 0.0448981374502182\n",
      "epoch: 7, step: 100, loss: 0.07523659616708755\n",
      "epoch: 7, step: 200, loss: 0.059704456478357315\n",
      "epoch: 8, step: 0, loss: 0.04138830676674843\n",
      "epoch: 8, step: 100, loss: 0.02592090144753456\n",
      "epoch: 8, step: 200, loss: 0.0191518422216177\n",
      "epoch: 9, step: 0, loss: 0.03952105715870857\n",
      "epoch: 9, step: 100, loss: 0.021765869110822678\n",
      "epoch: 9, step: 200, loss: 0.03404867276549339\n",
      "0:07:06.485267\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last = True,\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_RNN(batch['data'].to(device))\n",
    "        loss = loss_func(predict.view(-1, n_classes),\n",
    "                         batch['target'].to(device).view(-1),\n",
    "                         )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "\n",
    "    torch.save(model_RNN.state_dict(), f'./data/chkpt/rnn_chkpt_{epoch}.pth')\n",
    "end = datetime.datetime.now() - start\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#example\n",
    "phrase = 'He ran quickly after the red bus and caught it'\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_RNN.eval()\n",
    "    predict = model_RNN(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "print([rus[target_labels[l]] for l in labels])\n",
    "print(end)"
   ],
   "metadata": {
    "id": "K_PACmDaH8Z7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668446787330,
     "user_tz": -180,
     "elapsed": 2,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['местоимение', 'глагол', 'наречие', 'послелог', 'определитель', 'прилагательное', 'существительное', 'союз сочинительный', 'глагол', 'местоимение']\n",
      "0:00:00.001998\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['местоимение', 'существительное', 'наречие', 'глагол', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'союз подчинительный', 'местоимение', 'вспомогательный глагол', 'прилагательное', 'существительное']\n",
      "0:00:00.001996\n"
     ]
    }
   ],
   "source": [
    "#example 2\n",
    "phrase = 'My mother seldom watches TV in the living-room , because she has little time'\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_RNN.eval()\n",
    "    predict = model_RNN(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "print([rus[target_labels[l]] for l in labels])\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "class LSTMpredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x) # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
    "        hidden = self.do(hidden)\n",
    "        pred = self.clf(hidden) # B x T x N_classes\n",
    "\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "model_LSTM = LSTMpredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
    "model_LSTM.train()\n",
    "optim = torch.optim.Adam(model_LSTM.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 3.076673984527588\n",
      "epoch: 0, step: 100, loss: 0.40494850277900696\n",
      "epoch: 0, step: 200, loss: 0.2414265125989914\n",
      "epoch: 1, step: 0, loss: 0.16726931929588318\n",
      "epoch: 1, step: 100, loss: 0.1789942979812622\n",
      "epoch: 1, step: 200, loss: 0.18894536793231964\n",
      "epoch: 2, step: 0, loss: 0.08657508343458176\n",
      "epoch: 2, step: 100, loss: 0.13518747687339783\n",
      "epoch: 2, step: 200, loss: 0.07422366738319397\n",
      "epoch: 3, step: 0, loss: 0.10222505778074265\n",
      "epoch: 3, step: 100, loss: 0.08617609739303589\n",
      "epoch: 3, step: 200, loss: 0.08567441999912262\n",
      "epoch: 4, step: 0, loss: 0.06699670851230621\n",
      "epoch: 4, step: 100, loss: 0.07051361352205276\n",
      "epoch: 4, step: 200, loss: 0.08865643292665482\n",
      "epoch: 5, step: 0, loss: 0.06983352452516556\n",
      "epoch: 5, step: 100, loss: 0.04261178895831108\n",
      "epoch: 5, step: 200, loss: 0.06174503266811371\n",
      "epoch: 6, step: 0, loss: 0.06081746146082878\n",
      "epoch: 6, step: 100, loss: 0.05795649439096451\n",
      "epoch: 6, step: 200, loss: 0.054258719086647034\n",
      "epoch: 7, step: 0, loss: 0.037991296499967575\n",
      "epoch: 7, step: 100, loss: 0.025635801255702972\n",
      "epoch: 7, step: 200, loss: 0.05355984717607498\n",
      "epoch: 8, step: 0, loss: 0.027690252289175987\n",
      "epoch: 8, step: 100, loss: 0.03023083508014679\n",
      "epoch: 8, step: 200, loss: 0.037380196154117584\n",
      "epoch: 9, step: 0, loss: 0.0338616818189621\n",
      "epoch: 9, step: 100, loss: 0.036723941564559937\n",
      "epoch: 9, step: 200, loss: 0.029119916260242462\n",
      "0:21:24.343083\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last = True,\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_LSTM(batch['data'].to(device))\n",
    "        loss = loss_func(predict.view(-1, n_classes),\n",
    "                         batch['target'].to(device).view(-1),\n",
    "                         )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "\n",
    "    torch.save(model_LSTM.state_dict(), f'./data/chkpt/lstm_chkpt_{epoch}.pth')\n",
    "end = datetime.datetime.now() - start\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['местоимение', 'глагол', 'наречие', 'послелог', 'определитель', 'прилагательное', 'существительное', 'союз сочинительный', 'глагол', 'местоимение']\n",
      "0:00:00.002128\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "phrase = 'He ran quickly after the red bus and caught it'\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_LSTM.eval()\n",
    "    predict = model_LSTM(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "print([rus[target_labels[l]] for l in labels])\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['местоимение', 'существительное', 'наречие', 'существительное', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'союз подчинительный', 'местоимение', 'вспомогательный глагол', 'прилагательное', 'существительное']\n",
      "0:00:00.001998\n"
     ]
    }
   ],
   "source": [
    "#example 2\n",
    "phrase = 'My mother seldom watches TV in the living-room , because she has little time'\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_LSTM.eval()\n",
    "    predict = model_LSTM(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "print([rus[target_labels[l]] for l in labels])\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GRU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GRUPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x) # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
    "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
    "\n",
    "        return pred"
   ],
   "metadata": {
    "id": "9PbgCjN48FRe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_GRU = GRUPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
    "model_GRU.train()\n",
    "optim = torch.optim.Adam(model_GRU.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "id": "74gggSX58Fe9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.96183443069458\n",
      "epoch: 0, step: 100, loss: 0.2988634407520294\n",
      "epoch: 0, step: 200, loss: 0.17352457344532013\n",
      "epoch: 1, step: 0, loss: 0.19690696895122528\n",
      "epoch: 1, step: 100, loss: 0.1286381036043167\n",
      "epoch: 1, step: 200, loss: 0.12719474732875824\n",
      "epoch: 2, step: 0, loss: 0.16245992481708527\n",
      "epoch: 2, step: 100, loss: 0.09611711651086807\n",
      "epoch: 2, step: 200, loss: 0.12764838337898254\n",
      "epoch: 3, step: 0, loss: 0.060830000787973404\n",
      "epoch: 3, step: 100, loss: 0.12090741097927094\n",
      "epoch: 3, step: 200, loss: 0.11750597506761551\n",
      "epoch: 4, step: 0, loss: 0.07578935474157333\n",
      "epoch: 4, step: 100, loss: 0.065404511988163\n",
      "epoch: 4, step: 200, loss: 0.07084160298109055\n",
      "epoch: 5, step: 0, loss: 0.07452517002820969\n",
      "epoch: 5, step: 100, loss: 0.03176399692893028\n",
      "epoch: 5, step: 200, loss: 0.04402024671435356\n",
      "epoch: 6, step: 0, loss: 0.06112167611718178\n",
      "epoch: 6, step: 100, loss: 0.04922901839017868\n",
      "epoch: 6, step: 200, loss: 0.032067298889160156\n",
      "epoch: 7, step: 0, loss: 0.02813326194882393\n",
      "epoch: 7, step: 100, loss: 0.042241908609867096\n",
      "epoch: 7, step: 200, loss: 0.044540636241436005\n",
      "epoch: 8, step: 0, loss: 0.04331929609179497\n",
      "epoch: 8, step: 100, loss: 0.04224785417318344\n",
      "epoch: 8, step: 200, loss: 0.0298130065202713\n",
      "epoch: 9, step: 0, loss: 0.030790068209171295\n",
      "epoch: 9, step: 100, loss: 0.0352812297642231\n",
      "epoch: 9, step: 200, loss: 0.027894891798496246\n",
      "0:16:21.744449\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last = True,\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_GRU(batch['data'].to(device))\n",
    "        loss = loss_func(predict.view(-1, n_classes),\n",
    "                         batch['target'].to(device).view(-1),\n",
    "                         )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "\n",
    "    torch.save(model_GRU.state_dict(), f'./data/chkpt/gru_chkpt_{epoch}.pth')\n",
    "end = datetime.datetime.now() - start\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['местоимение', 'глагол', 'наречие', 'послелог', 'определитель', 'прилагательное', 'существительное', 'союз сочинительный', 'глагол', 'местоимение']\n",
      "0:00:00.003997\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "phrase = 'He ran quickly after the red bus and caught it'\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_GRU.eval()\n",
    "    predict = model_GRU(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "print([rus[target_labels[l]] for l in labels])\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['местоимение', 'существительное', 'наречие', 'глагол', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'союз подчинительный', 'местоимение', 'вспомогательный глагол', 'прилагательное', 'существительное']\n",
      "0:00:00.002999\n"
     ]
    }
   ],
   "source": [
    "#example 2\n",
    "phrase = 'My mother seldom watches TV in the living-room , because she has little time'\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_GRU.eval()\n",
    "    predict = model_GRU(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "print([rus[target_labels[l]] for l in labels])\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат RNN модели:\n",
      " ['местоимение', 'глагол', 'послелог', 'определитель', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'союз сочинительный', 'числительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'имя собственное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'существительное', 'послелог', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'наречие', 'прилагательное', 'союз сочинительный', 'глагол', 'наречие', 'послелог', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'наречие', 'глагол', 'послелог', 'местоимение', 'пунктуация', 'местоимение', 'глагол', 'послелог', 'имя собственное', 'союз подчинительный', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'прилагательное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'прилагательное', 'пунктуация']\n",
      "Время предсказания: 0:00:00.006995\n",
      "Результат LSTM модели:\n",
      " ['местоимение', 'глагол', 'послелог', 'определитель', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'союз сочинительный', 'числительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'глагол', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'существительное', 'послелог', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'наречие', 'прилагательное', 'союз сочинительный', 'глагол', 'наречие', 'послелог', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'наречие', 'глагол', 'послелог', 'местоимение', 'пунктуация', 'местоимение', 'глагол', 'послелог', 'имя собственное', 'наречие', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'прилагательное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'прилагательное', 'пунктуация']\n",
      "Время предсказания: 0:00:00.010996\n",
      "Результат GRU модели:\n",
      " ['местоимение', 'глагол', 'послелог', 'определитель', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'союз сочинительный', 'числительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'глагол', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'существительное', 'послелог', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'наречие', 'прилагательное', 'союз сочинительный', 'глагол', 'наречие', 'послелог', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'наречие', 'глагол', 'послелог', 'местоимение', 'пунктуация', 'местоимение', 'глагол', 'послелог', 'имя собственное', 'наречие', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'прилагательное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'прилагательное', 'пунктуация']\n",
      "Время предсказания: 0:00:00.011001\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "phrase = r\"I live in a house near the mountains. I have two brothers and one sister, and I was born last. My father teaches mathematics, and my mother is a nurse at a big hospital. My brothers are very smart and work hard in school. My sister is a nervous girl, but she is very kind. My grandmother also lives with us. She came from Italy when I was two years old. She has grown old, but she is still very strong.\"\n",
    "phrase = re.sub('([.,])', r' \\1', phrase)\n",
    "words = phrase.split(' ')\n",
    "tokens = [dataset.word_vocab[w] for w in words]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_RNN.eval()\n",
    "    predict = model_RNN(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "RNN_pred = [rus[target_labels[l]] for l in labels]\n",
    "print(f'Результат RNN модели:\\n {RNN_pred}')\n",
    "print(f'Время предсказания: {end}')\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_LSTM.eval()\n",
    "    predict = model_LSTM(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "LSTM_pred = [rus[target_labels[l]] for l in labels]\n",
    "print(f'Результат LSTM модели:\\n {LSTM_pred}')\n",
    "print(f'Время предсказания: {end}')\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_GRU.eval()\n",
    "    predict = model_GRU(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "GRU_pred = [rus[target_labels[l]] for l in labels]\n",
    "print(f'Результат GRU модели:\\n {GRU_pred}')\n",
    "print(f'Время предсказания: {end}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_pred == LSTM_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_pred == GRU_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_pred == LSTM_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: teaches \n",
      "предсказание RNN: имя собственное \n",
      "предсказание LSTM: глагол\n",
      "предсказание GRU: глагол\n",
      "Слово: when \n",
      "предсказание RNN: союз подчинительный \n",
      "предсказание LSTM: наречие\n",
      "предсказание GRU: наречие\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(RNN_pred):\n",
    "    if pred != LSTM_pred[i]:\n",
    "        print(f'Слово: {words[i]} \\n'\n",
    "              f'предсказание RNN: {pred} \\n'\n",
    "              f'предсказание LSTM: {LSTM_pred[i]}\\n'\n",
    "              f'предсказание GRU: {GRU_pred[i]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод:** самая быстрая в обучении модель RNN, она же самая быстрая в предсказании. На тестовом примере LSTM и GRU показали одинаковые результаты, при этом, GRU учится быстрее. Сеть на базе RNN допустила 2 ошибки"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN с bidirectional"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class RNNPredictor_bi_dir(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.clf = nn.Linear(hidden_dim*2, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x) # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
    "        hidden = self.do(hidden)\n",
    "        pred = self.clf(hidden) # B x T x N_classes\n",
    "\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "model_RNN_bi_dir = RNNPredictor_bi_dir(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
    "model_RNN_bi_dir.train()\n",
    "optim = torch.optim.Adam(model_RNN_bi_dir.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 3.1407840251922607\n",
      "epoch: 0, step: 100, loss: 0.20730912685394287\n",
      "epoch: 0, step: 200, loss: 0.18161946535110474\n",
      "epoch: 1, step: 0, loss: 0.21676044166088104\n",
      "epoch: 1, step: 100, loss: 0.11265759915113449\n",
      "epoch: 1, step: 200, loss: 0.11493123322725296\n",
      "epoch: 2, step: 0, loss: 0.0695004090666771\n",
      "epoch: 2, step: 100, loss: 0.12229912728071213\n",
      "epoch: 2, step: 200, loss: 0.062385689467191696\n",
      "epoch: 3, step: 0, loss: 0.06956055760383606\n",
      "epoch: 3, step: 100, loss: 0.05425114184617996\n",
      "epoch: 3, step: 200, loss: 0.07239409536123276\n",
      "epoch: 4, step: 0, loss: 0.0769365131855011\n",
      "epoch: 4, step: 100, loss: 0.04254380613565445\n",
      "epoch: 4, step: 200, loss: 0.04885401204228401\n",
      "epoch: 5, step: 0, loss: 0.054897937923669815\n",
      "epoch: 5, step: 100, loss: 0.04962540417909622\n",
      "epoch: 5, step: 200, loss: 0.03757314011454582\n",
      "epoch: 6, step: 0, loss: 0.03546896204352379\n",
      "epoch: 6, step: 100, loss: 0.03118445724248886\n",
      "epoch: 6, step: 200, loss: 0.03003990463912487\n",
      "epoch: 7, step: 0, loss: 0.03367948159575462\n",
      "epoch: 7, step: 100, loss: 0.03648390620946884\n",
      "epoch: 7, step: 200, loss: 0.04296523705124855\n",
      "epoch: 8, step: 0, loss: 0.02288091741502285\n",
      "epoch: 8, step: 100, loss: 0.023555828258395195\n",
      "epoch: 8, step: 200, loss: 0.03641273081302643\n",
      "epoch: 9, step: 0, loss: 0.01663692109286785\n",
      "epoch: 9, step: 100, loss: 0.024749914184212685\n",
      "epoch: 9, step: 200, loss: 0.008622609078884125\n",
      "0:11:55.677455\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last = True,\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_RNN_bi_dir(batch['data'].to(device))\n",
    "        loss = loss_func(predict.view(-1, n_classes),\n",
    "                         batch['target'].to(device).view(-1),\n",
    "                         )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "\n",
    "    torch.save(model_RNN_bi_dir.state_dict(), f'./data/chkpt/rnn_bi_dir_chkpt_{epoch}.pth')\n",
    "end = datetime.datetime.now() - start\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM c bidirectional"
   ],
   "metadata": {
    "id": "-57Jq-CW8NmD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "class LSTMpredictor_bi_dir(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.clf = nn.Linear(hidden_dim*2, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x) # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
    "        hidden = self.do(hidden)\n",
    "        pred = self.clf(hidden) # B x T x N_classes\n",
    "\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "model_LSTM_bi_dir = LSTMpredictor_bi_dir(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
    "model_LSTM_bi_dir.train()\n",
    "optim = torch.optim.Adam(model_LSTM_bi_dir.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.925898790359497\n",
      "epoch: 0, step: 100, loss: 0.21059846878051758\n",
      "epoch: 0, step: 200, loss: 0.1369604617357254\n",
      "epoch: 1, step: 0, loss: 0.1001410186290741\n",
      "epoch: 1, step: 100, loss: 0.14304573833942413\n",
      "epoch: 1, step: 200, loss: 0.12774835526943207\n",
      "epoch: 2, step: 0, loss: 0.08160749822854996\n",
      "epoch: 2, step: 100, loss: 0.06445468217134476\n",
      "epoch: 2, step: 200, loss: 0.05662434920668602\n",
      "epoch: 3, step: 0, loss: 0.05439642071723938\n",
      "epoch: 3, step: 100, loss: 0.05366320535540581\n",
      "epoch: 3, step: 200, loss: 0.05912519991397858\n",
      "epoch: 4, step: 0, loss: 0.035853032022714615\n",
      "epoch: 4, step: 100, loss: 0.04357300326228142\n",
      "epoch: 4, step: 200, loss: 0.0528816320002079\n",
      "epoch: 5, step: 0, loss: 0.024363698437809944\n",
      "epoch: 5, step: 100, loss: 0.030885355547070503\n",
      "epoch: 5, step: 200, loss: 0.03241448476910591\n",
      "epoch: 6, step: 0, loss: 0.02153574489057064\n",
      "epoch: 6, step: 100, loss: 0.018643667921423912\n",
      "epoch: 6, step: 200, loss: 0.013470453210175037\n",
      "epoch: 7, step: 0, loss: 0.019487978890538216\n",
      "epoch: 7, step: 100, loss: 0.013480780646204948\n",
      "epoch: 7, step: 200, loss: 0.015592134557664394\n",
      "epoch: 8, step: 0, loss: 0.006547392345964909\n",
      "epoch: 8, step: 100, loss: 0.010563109070062637\n",
      "epoch: 8, step: 200, loss: 0.013742136768996716\n",
      "epoch: 9, step: 0, loss: 0.005622303579002619\n",
      "epoch: 9, step: 100, loss: 0.006865778937935829\n",
      "epoch: 9, step: 200, loss: 0.006656247191131115\n",
      "0:42:21.432434\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last=True,\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_LSTM_bi_dir(batch['data'].to(device))\n",
    "        loss = loss_func(predict.view(-1, n_classes),\n",
    "                         batch['target'].to(device).view(-1),\n",
    "                         )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "\n",
    "    torch.save(model_LSTM_bi_dir.state_dict(), f'./data/chkpt/lstm_chkpt_{epoch}.pth')\n",
    "end = datetime.datetime.now() - start\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GRU c bidirectional"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "class GRUPredictor_bi_dir(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.clf = nn.Linear(hidden_dim*2, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x)  # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb)  # B x T x Hid, B x 1 x Hid\n",
    "        pred = self.clf(self.do(hidden))  # B x T x N_classes\n",
    "\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "model_GRU_bi_dir = GRUPredictor_bi_dir(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
    "model_GRU_bi_dir.train()\n",
    "optim = torch.optim.Adam(model_GRU_bi_dir.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 2.8381030559539795\n",
      "epoch: 0, step: 100, loss: 0.22998511791229248\n",
      "epoch: 0, step: 200, loss: 0.20958945155143738\n",
      "epoch: 1, step: 0, loss: 0.14291366934776306\n",
      "epoch: 1, step: 100, loss: 0.11516620218753815\n",
      "epoch: 1, step: 200, loss: 0.09671066701412201\n",
      "epoch: 2, step: 0, loss: 0.0654531717300415\n",
      "epoch: 2, step: 100, loss: 0.0889594629406929\n",
      "epoch: 2, step: 200, loss: 0.06926024705171585\n",
      "epoch: 3, step: 0, loss: 0.05963835120201111\n",
      "epoch: 3, step: 100, loss: 0.06701663881540298\n",
      "epoch: 3, step: 200, loss: 0.060355450958013535\n",
      "epoch: 4, step: 0, loss: 0.037076883018016815\n",
      "epoch: 4, step: 100, loss: 0.05435841530561447\n",
      "epoch: 4, step: 200, loss: 0.042370568960905075\n",
      "epoch: 5, step: 0, loss: 0.03276119381189346\n",
      "epoch: 5, step: 100, loss: 0.029102355241775513\n",
      "epoch: 5, step: 200, loss: 0.03584596887230873\n",
      "epoch: 6, step: 0, loss: 0.021334558725357056\n",
      "epoch: 6, step: 100, loss: 0.02521331049501896\n",
      "epoch: 6, step: 200, loss: 0.02247072197496891\n",
      "epoch: 7, step: 0, loss: 0.013492466881871223\n",
      "epoch: 7, step: 100, loss: 0.01982620730996132\n",
      "epoch: 7, step: 200, loss: 0.020083073526620865\n",
      "epoch: 8, step: 0, loss: 0.01631874404847622\n",
      "epoch: 8, step: 100, loss: 0.01268539298325777\n",
      "epoch: 8, step: 200, loss: 0.007412067148834467\n",
      "epoch: 9, step: 0, loss: 0.010764451697468758\n",
      "epoch: 9, step: 100, loss: 0.006848882418125868\n",
      "epoch: 9, step: 200, loss: 0.007799393031746149\n",
      "0:33:34.239103\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last=True,\n",
    "                            )\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        predict = model_GRU_bi_dir(batch['data'].to(device))\n",
    "        loss = loss_func(predict.view(-1, n_classes),\n",
    "                         batch['target'].to(device).view(-1),\n",
    "                         )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "\n",
    "    torch.save(model_GRU_bi_dir.state_dict(), f'./data/chkpt/gru_chkpt_{epoch}.pth')\n",
    "end = datetime.datetime.now() - start\n",
    "print(end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сравнение"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат RNN модели c bidirectional:\n",
      " ['местоимение', 'глагол', 'послелог', 'определитель', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'местоимение', 'глагол', 'числительное', 'существительное', 'союз сочинительный', 'числительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'глагол', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'существительное', 'послелог', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'наречие', 'прилагательное', 'союз сочинительный', 'глагол', 'наречие', 'послелог', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'пунктуация', 'местоимение', 'существительное', 'наречие', 'глагол', 'послелог', 'местоимение', 'пунктуация', 'местоимение', 'глагол', 'послелог', 'имя собственное', 'союз подчинительный', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'прилагательное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'прилагательное', 'пунктуация']\n",
      "Время предсказания: 0:00:00.012099\n",
      "Результат LSTM модели c bidirectional:\n",
      " ['местоимение', 'глагол', 'послелог', 'определитель', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'местоимение', 'глагол', 'числительное', 'существительное', 'союз сочинительный', 'числительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'существительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'существительное', 'послелог', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'наречие', 'прилагательное', 'союз сочинительный', 'глагол', 'наречие', 'послелог', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'наречие', 'глагол', 'послелог', 'местоимение', 'пунктуация', 'местоимение', 'глагол', 'послелог', 'имя собственное', 'наречие', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'прилагательное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'прилагательное', 'пунктуация']\n",
      "Время предсказания: 0:00:00.029302\n",
      "Результат GRU модели c bidirectional:\n",
      " ['местоимение', 'глагол', 'послелог', 'определитель', 'существительное', 'послелог', 'определитель', 'существительное', 'пунктуация', 'местоимение', 'глагол', 'числительное', 'существительное', 'союз сочинительный', 'числительное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'послелог', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'существительное', 'послелог', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'наречие', 'прилагательное', 'союз сочинительный', 'глагол', 'наречие', 'послелог', 'существительное', 'пунктуация', 'местоимение', 'существительное', 'вспомогательный глагол', 'определитель', 'прилагательное', 'существительное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'прилагательное', 'пунктуация', 'местоимение', 'существительное', 'наречие', 'глагол', 'послелог', 'местоимение', 'пунктуация', 'местоимение', 'глагол', 'послелог', 'имя собственное', 'наречие', 'местоимение', 'вспомогательный глагол', 'числительное', 'существительное', 'прилагательное', 'пунктуация', 'местоимение', 'вспомогательный глагол', 'глагол', 'прилагательное', 'пунктуация', 'союз сочинительный', 'местоимение', 'вспомогательный глагол', 'наречие', 'наречие', 'прилагательное', 'пунктуация']\n",
      "Время предсказания: 0:00:00.021296\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_RNN_bi_dir.eval()\n",
    "    predict = model_RNN_bi_dir(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "RNN_pred_bi_dir = [rus[target_labels[l]] for l in labels]\n",
    "print(f'Результат RNN модели c bidirectional:\\n {RNN_pred_bi_dir}')\n",
    "print(f'Время предсказания: {end}')\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_LSTM_bi_dir.eval()\n",
    "    predict = model_LSTM_bi_dir(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "LSTM_pred_bi_dir = [rus[target_labels[l]] for l in labels]\n",
    "print(f'Результат LSTM модели c bidirectional:\\n {LSTM_pred_bi_dir}')\n",
    "print(f'Время предсказания: {end}')\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_GRU_bi_dir.eval()\n",
    "    predict = model_GRU_bi_dir(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
    "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
    "    end = datetime.datetime.now() - start\n",
    "\n",
    "target_labels = list(dataset.target_vocab.keys())\n",
    "GRU_pred_bi_dir = [rus[target_labels[l]] for l in labels]\n",
    "print(f'Результат GRU модели c bidirectional:\\n {GRU_pred_bi_dir}')\n",
    "print(f'Время предсказания: {end}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_pred_bi_dir == RNN_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_pred_bi_dir == LSTM_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_pred_bi_dir == GRU_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: have \n",
      "предсказание RNN c bidirectional: глагол \n",
      "предсказание RNN: вспомогательный глагол \n",
      "предсказание LSTM c bidirectional: глагол\n",
      "предсказание LSTM: вспомогательный глагол\n",
      "предсказание GRU c bidirectional: глагол\n",
      "предсказание GRU: вспомогательный глагол\n",
      "Слово: kind \n",
      "предсказание RNN c bidirectional: наречие \n",
      "предсказание RNN: прилагательное \n",
      "предсказание LSTM c bidirectional: прилагательное\n",
      "предсказание LSTM: прилагательное\n",
      "предсказание GRU c bidirectional: прилагательное\n",
      "предсказание GRU: прилагательное\n",
      "Слово: when \n",
      "предсказание RNN c bidirectional: союз подчинительный \n",
      "предсказание RNN: союз подчинительный \n",
      "предсказание LSTM c bidirectional: наречие\n",
      "предсказание LSTM: наречие\n",
      "предсказание GRU c bidirectional: наречие\n",
      "предсказание GRU: наречие\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(RNN_pred_bi_dir):\n",
    "    if pred != LSTM_pred[i]:\n",
    "        print(f'Слово: {words[i]} \\n'\n",
    "              f'предсказание RNN c bidirectional: {pred} \\n'\n",
    "              f'предсказание RNN: {RNN_pred[i]} \\n'\n",
    "              f'предсказание LSTM c bidirectional: {LSTM_pred_bi_dir[i]}\\n'\n",
    "              f'предсказание LSTM: {LSTM_pred[i]}\\n'\n",
    "              f'предсказание GRU c bidirectional: {GRU_pred_bi_dir[i]}\\n'\n",
    "              f'предсказание GRU: {GRU_pred[i]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: have \n",
      "предсказание RNN c bidirectional: глагол \n",
      "предсказание RNN: вспомогательный глагол \n",
      "\n",
      "Слово: teaches \n",
      "предсказание RNN c bidirectional: глагол \n",
      "предсказание RNN: имя собственное \n",
      "\n",
      "Слово: kind \n",
      "предсказание RNN c bidirectional: наречие \n",
      "предсказание RNN: прилагательное \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(RNN_pred_bi_dir):\n",
    "    if pred != RNN_pred[i]:\n",
    "        print(f'Слово: {words[i]} \\n'\n",
    "              f'предсказание RNN c bidirectional: {pred} \\n'\n",
    "              f'предсказание RNN: {RNN_pred[i]} \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: have \n",
      "предсказание LSTM c bidirectional: глагол \n",
      "предсказание LSTM: вспомогательный глагол \n",
      "\n",
      "Слово: teaches \n",
      "предсказание LSTM c bidirectional: существительное \n",
      "предсказание LSTM: глагол \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(LSTM_pred_bi_dir):\n",
    "    if pred != LSTM_pred[i]:\n",
    "        print(f'Слово: {words[i]} \\n'\n",
    "              f'предсказание LSTM c bidirectional: {pred} \\n'\n",
    "              f'предсказание LSTM: {LSTM_pred[i]} \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: have \n",
      "предсказание GRU c bidirectional: глагол \n",
      "предсказание GRU: вспомогательный глагол \n",
      "\n",
      "Слово: teaches \n",
      "предсказание GRU c bidirectional: послелог \n",
      "предсказание GRU: глагол \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(GRU_pred_bi_dir):\n",
    "    if pred != GRU_pred[i]:\n",
    "        print(f'Слово: {words[i]} \\n'\n",
    "              f'предсказание GRU c bidirectional: {pred} \\n'\n",
    "              f'предсказание GRU: {GRU_pred[i]} \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод:** модели с bidirectional отработали хуже и ошиблись на тех словах, в которых ранее ошибок не было. Также, такие модели учатся и предсказывают значительно медленнее"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}